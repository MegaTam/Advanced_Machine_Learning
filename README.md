# Advanced_Machine_Learning

## Introduction
This project is used to detect the AI-Generated content.  
This report describes the development and evaluation of classifying AI-generated and human-generated text. Using integrated methods and extensive experiments, we identified key findings about classifier performance and model diversity. Overall, this research upholds academic and informational integrity against the rapid spread of AI-generated content.  

## Data
Our data comes from a Kaggle competition , saved as processed_data.csv. It contains 29,133 English texts with an average word count of about 382 words. Of these, 17,508 texts were generated by students (humans), labeled as "0", and 11,625 by an LLM, labeled as "1".  
A Tokenizer is a disambiguator used to transform textual data into numerical data. Its principle is to construct a dictionary table by sorting the text dataset according to the frequency of occurrence of words. The text dataset is then transformed into numerical data represented by the current word occurrence frequency.

## Model
We constructed a Stacking model using KNN and Random Forest as the base learner and Logistic Regression as the meta-learner.  
We also used Tokenizer and Text-CNN to construct another classifier.

## Results
Logistic Regression(LR): Accuracy: 0.5986, Recall: 1.000.  
K-Nearest Neighbors (KNN): Accuracy: 0.67245, Recall: 0.7556.  
Random Forest: Accuracy: 0.7166, Recall: 0.8509.  
Stacking: Accuracy: 0.7139, Recall: 1.000.  
Text-CNN: Accuracy: 0.6605, Recall: 0.6915.
